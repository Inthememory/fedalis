{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "retailers_with_id = [\n",
    "        \"coup_de_pates\",\n",
    "        \"ds_restauration\",\n",
    "        \"even\",\n",
    "        \"metro\",\n",
    "        \"pomona\",\n",
    "        \"pro_a_pro\",\n",
    "        \"sysco\",\n",
    "        \"transgourmet\",\n",
    "    ]\n",
    "retailers_without_id = [\n",
    "        \"ducreux\",\n",
    "        \"relais_dor\",\n",
    "    ]\n",
    "\n",
    "retailers = retailers_with_id + retailers_without_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract products sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "for retailer_with_id in retailers_with_id:\n",
    "    dataset = pl.read_parquet(f'data/silver/with_id/{retailer_with_id}.parquet')\n",
    "    dataset = dataset.unique(subset=[c for c in dataset.columns if c.startswith('level') or c == 'volume_unit']).with_columns(pl.lit(retailer_with_id).alias('retailer'))\n",
    "    datasets.append(dataset)\n",
    "\n",
    "dataset_concat = pl.concat(datasets)\n",
    "dataset_concat = dataset_concat.sort(['retailer']+ [c for c in dataset_concat.columns if c.startswith('level')] + ['volume_unit'])\n",
    "\n",
    "dataset_concat.write_csv('data/log/model_4/products_subset_withId.csv', separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "for retailer_without_id in retailers_without_id:\n",
    "    dataset = pl.read_parquet(f'data/silver/without_id/{retailer_without_id}.parquet')\n",
    "    dataset = dataset.unique(subset=[c for c in dataset.columns if c.startswith('level') or c == 'volume_unit']).with_columns(pl.lit(retailer_without_id).alias('retailer'))\n",
    "    datasets.append(dataset)\n",
    "\n",
    "dataset_concat = pl.concat(datasets)\n",
    "dataset_concat = dataset_concat.sort(['retailer']+ [c for c in dataset_concat.columns if c.startswith('level')] + ['volume_unit'])\n",
    "\n",
    "dataset_concat.write_csv('data/log/model_4/products_subset_withoutId.csv', separator=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract volume unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "for retailer in retailers:\n",
    "    if retailer in retailers_with_id:\n",
    "        dataset = pl.read_parquet(f'data/silver/with_id/{retailer}.parquet')\n",
    "    else :\n",
    "        dataset = pl.read_parquet(f'data/silver/without_id/{retailer}.parquet')\n",
    "\n",
    "    dataset = dataset.select('volume_unit').unique().with_columns(pl.lit(retailer).alias('retailer'))\n",
    "    datasets.append(dataset)\n",
    "\n",
    "dataset_concat = pl.concat(datasets).select('retailer', 'volume_unit').sort('retailer')\n",
    "dataset_concat.write_csv('data/log/model_4/volume_unit_subset.csv', separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "\n",
    "from src.utils.profiling import incremental_sublists\n",
    "\n",
    "retailers_with_id = [\n",
    "        \"coup_de_pates\",\n",
    "        \"ds_restauration\",\n",
    "        \"even\",\n",
    "        \"metro\",\n",
    "        \"pomona\",\n",
    "        \"pro_a_pro\",\n",
    "        \"sysco\",\n",
    "        \"transgourmet\",\n",
    "    ]\n",
    "retailers_without_id = [\n",
    "        \"ducreux\",\n",
    "        \"relais_dor\",\n",
    "    ]\n",
    "\n",
    "retailers = retailers_with_id + retailers_without_id\n",
    "\n",
    "wb = xlsxwriter.Workbook(\n",
    "            f\"data/log/model_4/volume_unit_subset_detailed.xlsx\"\n",
    "        )\n",
    "\n",
    "\n",
    "agg_cols_lst = incremental_sublists([f'level_{i}_standard' for i in range(1, 5)])\n",
    "for i, agg_cols in enumerate(agg_cols_lst, start=1):\n",
    "\n",
    "    datasets = []\n",
    "    for retailer in retailers:\n",
    "        if retailer in retailers_with_id:\n",
    "            dataset = pl.read_parquet(f'data/silver/with_id/{retailer}.parquet').rename(lambda column_name: column_name.replace(f\"_{retailer}\", \"\"))\n",
    "            product_col = 'product_id'\n",
    "        else :\n",
    "            dataset = pl.read_parquet(f'data/silver/without_id/{retailer}.parquet').rename(lambda column_name: column_name.replace(f\"_{retailer}\", \"\"))\n",
    "            product_col = 'product_code'\n",
    "\n",
    "        dataset = dataset.group_by(['volume_unit'] + agg_cols).agg(pl.col(product_col).n_unique().alias('nb_products')).unique().with_columns(pl.lit(retailer).alias('retailer')).sort(agg_cols + ['retailer', 'volume_unit'])\n",
    "        datasets.append(dataset)\n",
    "\n",
    "    dataset_concat = pl.concat(datasets)\n",
    "    dataset_concat.write_excel(workbook=wb, worksheet=f\"level_{i}\")\n",
    "\n",
    "wb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volume from product name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('500', 'G', '')]\n",
      "[('500', 'G', '')]\n",
      "[('500', 'G', '')]\n",
      "[('500', 'G', '')]\n",
      "[('500', 'G', 'x120')]\n",
      "[('500', 'G', 'X 120')]\n",
      "[('500.0', 'L', '')]\n",
      "[('500,11', 'CL', ''), ('500', 'ml', '')]\n",
      "[('500,11', 'CL', ''), ('500', 'ml', 'x100')]\n",
      "[('500,11', 'CL', ''), ('500', 'ml', 'x100')]\n",
      "[('500,11', 'CL', ''), ('500', 'ml', '')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'What This Regex Does\\n\\x08 → Ensures word boundary (matches only whole words).\\n(\\\\d+(?:\\\\.|,)*\\\\d*) → Captures a number with optional decimal/comma separators (e.g., \"500\", \"1.5\", \"2,5\").\\n\\\\s* → Allows optional spaces between number and unit.\\n(g|kg|ml|cl|l|gr) → Captures common measurement units.\\n\\x08 → Ensures the unit is a whole word.\\n\\\\s*(x\\\\s*\\\\d+)?\\x08 → Optionally captures a multiplier format (e.g., \"x 2\" in \"500 G x 2\").'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    \"LASAGNE AUX OEUFS BOITE 500 G BARILLA\",\n",
    "    \"LASAGNE AUX OEUFS BOITE 500G BARILLA\",\n",
    "    \"LASAGNE AUX OEUFS BOITE 500 G\",\n",
    "    \"LASAGNE AUX OEUFS BOITE 500G\",\n",
    "    \"LASAGNE AUX OEUFS BOITE 500 G x120\",\n",
    "    \"LASAGNE AUX OEUFS BOITE 500G X 120\",\n",
    "    \"LASAGNE AUX OEUFS BOITE 500.0 L\",\n",
    "    \"LASAGNE AUX OEUFS BOITE 500,11 CL 500 ml\",\n",
    "    \"LASAGNE AUX OEUFS BOITE 500,11 CL 500 ml x100\",\n",
    "    \"LASAGNE AUX OEUFS BOITE 500,11 CL 500 ml x100 BARILLA\",\n",
    "    \"LASAGNE AUX OEUFS BOITE 500,11 CL 500 ml x100BARILLA\"\n",
    "]\n",
    "\n",
    "pattern = r\"\\b(\\d+(?:\\.|,)*\\d*)\\s*(g|kg|ml|cl|l|gr)\\b\\s*(x\\s*\\d+)?\\b\"\n",
    "\n",
    "for text in texts:\n",
    "    match = re.findall(pattern, text, re.IGNORECASE)  # Case-insensitive matching\n",
    "#     match = re.search(pattern, text, re.IGNORECASE)  # Case-insensitive matching\n",
    "    if match:\n",
    "        print(match)\n",
    "        # print(match.group().upper())  # Extracted value\n",
    "\n",
    "\n",
    "\"\"\"What This Regex Does\n",
    "\\b → Ensures word boundary (matches only whole words).\n",
    "(\\d+(?:\\.|,)*\\d*) → Captures a number with optional decimal/comma separators (e.g., \"500\", \"1.5\", \"2,5\").\n",
    "\\s* → Allows optional spaces between number and unit.\n",
    "(g|kg|ml|cl|l|gr) → Captures common measurement units.\n",
    "\\b → Ensures the unit is a whole word.\n",
    "\\s*(x\\s*\\d+)?\\b → Optionally captures a multiplier format (e.g., \"x 2\" in \"500 G x 2\").\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pl.Config.set_fmt_str_lengths(100)\n",
    "\n",
    "# def extract_volume(text:str)->list:\n",
    "#     pattern = r\"\\b(\\d+(?:\\.|,)*\\d*)\\s*(g|kg|ml|cl|l|gr)\\b\\s*(x\\s*\\d+)?\\b\"\n",
    "#     matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "#     return matches if matches else []\n",
    "\n",
    "# retailer = 'coup_de_pates'\n",
    "# with pl.Config(tbl_rows=-1):\n",
    "#     display(\n",
    "#         pl.read_parquet(f'data/silver/with_id/{retailer}.parquet')\n",
    "#         .filter(pl.col('volume_unit_even')==\"UNT  \")\n",
    "#         # .filter(pl.col('level_3_standard_even')=='PATE')\n",
    "#         .with_columns(pl.col(f'product_name_{retailer}').map_elements(lambda x : extract_volume(x)).alias('new_volume_unit'))\n",
    "#         .select(f'product_name_{retailer}', 'new_volume_unit')\n",
    "#         # .filter(pl.col('new_volume_unit')==[])\n",
    "#         .sample(n=40)\n",
    "#         )\n",
    "# # .filter(pl.col('level_3_standard_even')=='PATE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volume <=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>retailer</th><th>v0tp</th><th>v0tn</th><th>v0t0</th><th>vntp</th><th>vntn</th><th>vptn</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;coup_de_pates&quot;</td><td>38</td><td>88</td><td>1</td><td>4</td><td>615</td><td>4</td></tr><tr><td>&quot;ds_restauration&quot;</td><td>13</td><td>19</td><td>2069</td><td>2</td><td>104</td><td>6</td></tr><tr><td>&quot;even&quot;</td><td>51</td><td>46</td><td>1113</td><td>5</td><td>879</td><td>10</td></tr><tr><td>&quot;metro&quot;</td><td>14111</td><td>489</td><td>4301</td><td>21</td><td>3479</td><td>71</td></tr><tr><td>&quot;pomona&quot;</td><td>468</td><td>736</td><td>12365</td><td>31</td><td>4750</td><td>105</td></tr><tr><td>&quot;pro_a_pro&quot;</td><td>231</td><td>715</td><td>0</td><td>17</td><td>4246</td><td>66</td></tr><tr><td>&quot;sysco&quot;</td><td>219</td><td>926</td><td>532932</td><td>5</td><td>2695</td><td>57</td></tr><tr><td>&quot;transgourmet&quot;</td><td>264</td><td>166</td><td>5832</td><td>10</td><td>1943</td><td>35</td></tr><tr><td>&quot;ducreux&quot;</td><td>40</td><td>79</td><td>1964</td><td>0</td><td>557</td><td>6</td></tr><tr><td>&quot;relais_dor&quot;</td><td>3434</td><td>315</td><td>0</td><td>19</td><td>1895</td><td>23</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 7)\n",
       "┌─────────────────┬───────┬──────┬────────┬──────┬──────┬──────┐\n",
       "│ retailer        ┆ v0tp  ┆ v0tn ┆ v0t0   ┆ vntp ┆ vntn ┆ vptn │\n",
       "│ ---             ┆ ---   ┆ ---  ┆ ---    ┆ ---  ┆ ---  ┆ ---  │\n",
       "│ str             ┆ i64   ┆ i64  ┆ i64    ┆ i64  ┆ i64  ┆ i64  │\n",
       "╞═════════════════╪═══════╪══════╪════════╪══════╪══════╪══════╡\n",
       "│ coup_de_pates   ┆ 38    ┆ 88   ┆ 1      ┆ 4    ┆ 615  ┆ 4    │\n",
       "│ ds_restauration ┆ 13    ┆ 19   ┆ 2069   ┆ 2    ┆ 104  ┆ 6    │\n",
       "│ even            ┆ 51    ┆ 46   ┆ 1113   ┆ 5    ┆ 879  ┆ 10   │\n",
       "│ metro           ┆ 14111 ┆ 489  ┆ 4301   ┆ 21   ┆ 3479 ┆ 71   │\n",
       "│ pomona          ┆ 468   ┆ 736  ┆ 12365  ┆ 31   ┆ 4750 ┆ 105  │\n",
       "│ pro_a_pro       ┆ 231   ┆ 715  ┆ 0      ┆ 17   ┆ 4246 ┆ 66   │\n",
       "│ sysco           ┆ 219   ┆ 926  ┆ 532932 ┆ 5    ┆ 2695 ┆ 57   │\n",
       "│ transgourmet    ┆ 264   ┆ 166  ┆ 5832   ┆ 10   ┆ 1943 ┆ 35   │\n",
       "│ ducreux         ┆ 40    ┆ 79   ┆ 1964   ┆ 0    ┆ 557  ┆ 6    │\n",
       "│ relais_dor      ┆ 3434  ┆ 315  ┆ 0      ┆ 19   ┆ 1895 ┆ 23   │\n",
       "└─────────────────┴───────┴──────┴────────┴──────┴──────┴──────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<xlsxwriter.workbook.Workbook at 0x279b9075090>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for retailer in retailers:\n",
    "    if retailer in retailers_with_id:\n",
    "        dataset = pl.read_parquet(f'data/silver/with_id/{retailer}.parquet')\n",
    "    else :\n",
    "        dataset = pl.read_parquet(f'data/silver/without_id/{retailer}.parquet')\n",
    "\n",
    "    if dataset.select(\"volume\").dtypes[0] == pl.String:\n",
    "        dataset = dataset.with_columns(\n",
    "            pl.col(\"volume\").str.replace(\",\", \".\").str.replace(\" \", \"\").cast(pl.Float64)\n",
    "        )\n",
    "\n",
    "    nb_rows_v0tp = dataset.filter((pl.col('volume')==0)|(pl.col('volume').is_null())).filter(pl.col('turnover')>0).shape[0]\n",
    "    nb_rows_v0tn = dataset.filter((pl.col('volume')==0)|(pl.col('volume').is_null())).filter(pl.col('turnover')<0).shape[0]\n",
    "    nb_rows_v0t0 = dataset.filter((pl.col('volume')==0)|(pl.col('volume').is_null())).filter((pl.col('turnover')==0)|(pl.col('turnover').is_null())).shape[0]\n",
    "    nb_rows_vntp = dataset.filter((pl.col('volume')<0)).filter(pl.col('turnover')>0).shape[0]\n",
    "    nb_rows_vntn = dataset.filter((pl.col('volume')<0)).filter(pl.col('turnover')<0).shape[0]\n",
    "    nb_rows_vptn = dataset.filter((pl.col('volume')>0)).filter(pl.col('turnover')<0).shape[0]\n",
    "    data.append(\n",
    "        {'retailer':retailer,\n",
    "         'v0tp': nb_rows_v0tp,\n",
    "         'v0tn': nb_rows_v0tn,\n",
    "         'v0t0': nb_rows_v0t0,\n",
    "         'vntp': nb_rows_vntp,\n",
    "         'vntn': nb_rows_vntn,\n",
    "         'vptn': nb_rows_vptn\n",
    "        })\n",
    "\n",
    "    # display(dataset.filter((pl.col('volume')<0)).filter(pl.col('turnover')>0).sample(n=1))\n",
    "res = pl.from_dicts(data)\n",
    "display(res)\n",
    "res.write_excel('volume_turnover_eda.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- coup_de_pates \n",
    "    - [Poids N] : volume vendu\n",
    "    - Unité Poids : unité de volume\n",
    "-> que en KG\n",
    "\n",
    "- ds_restauration\n",
    "    - Volume Vendu (kg) : volume vendu\n",
    "    - unité de volume : kg\n",
    "-> en KG/L\n",
    "\n",
    "- ducreux\n",
    "    - Poids net liv: volume vendu \n",
    "-> A transformer en KG/L\n",
    "\n",
    "- even \n",
    "    - Poids Saisi Livré: volume vendu en kg/L\n",
    "    - Qté / Poids Livré: volume en Unité de Facturation (kg, unité, L, ...)\n",
    "    - Unité de Facturation: volume_unit\n",
    "-> en KG/L\n",
    "Produits exprimés en litre en kg chez un autre \n",
    "\n",
    "- metro\n",
    "    - Poids_volume: volume\n",
    "    - unite_volume : unité de volume\n",
    "-> A transformer en KG/L + manquants\n",
    "\n",
    "- pomona\n",
    "    - Poids livré \n",
    "-> en KG/L ? \n",
    "\n",
    "- pro_a_pro\n",
    "    - Volume facturé: volume vendu\n",
    "-> en KG/L\n",
    "\n",
    "- relais_dor\n",
    "    - Poids \n",
    "-> en KG/L ? \n",
    "\n",
    "- sysco\n",
    "    - Quantité KG: volume vendu en kg\n",
    "-> en KG/L ? \n",
    "\n",
    "- transgourmet\n",
    "    - Poids Brut Facturé\n",
    "-> en KG/L ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "even = (\n",
    "    pl.read_parquet(\"data/silver/with_id/even.parquet\").select(\"product_id\", 'product_name', 'volume', 'volume_unit')\n",
    "    .rename(lambda col: f'{col}_even')\n",
    "    .rename({f'product_id_even': \"product_id\"})\n",
    ")\n",
    "\n",
    "metro = (\n",
    "    pl.read_parquet(\"data/silver/with_id/metro.parquet\").select(\"product_id\", 'product_name', 'volume', 'volume_unit')\n",
    "    .rename(lambda col: f'{col}_metro')\n",
    "    .rename({f'product_id_metro': \"product_id\"})\n",
    "    .with_columns(pl.col('volume_metro').cast(pl.Utf8).str.replace(\",\", \".\").cast(pl.Float64))\n",
    ")\n",
    "\n",
    "res = even.join(metro, on='product_id', how='inner').filter(pl.col('volume_unit_even')!=pl.col('volume_unit_metro')).unique(subset=['product_id'])\n",
    "res.with_columns(pl.col(\"product_id\").cast(pl.Utf8)).write_excel('volume_unit_inconsistencies.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
