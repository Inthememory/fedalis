{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "retailers_with_id = [\n",
    "        \"coup_de_pates\",\n",
    "        \"ds_restauration\",\n",
    "        \"even\",\n",
    "        \"metro\",\n",
    "        \"pomona\",\n",
    "        \"pro_a_pro\",\n",
    "        \"sysco\",\n",
    "        \"transgourmet\",\n",
    "    ]\n",
    "retailers_without_id = [\n",
    "        \"ducreux\",\n",
    "        \"relais_dor\",\n",
    "    ]\n",
    "\n",
    "retailers = retailers_with_id + retailers_without_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract products sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "for retailer_with_id in retailers_with_id:\n",
    "    dataset = pl.read_parquet(f'data/silver/with_id/{retailer_with_id}.parquet').rename(lambda column_name: column_name.replace(f\"_{retailer_with_id}\", \"\"))\n",
    "    dataset = dataset.unique(subset=[c for c in dataset.columns if c.startswith('level') or c == 'volume_unit']).with_columns(pl.lit(retailer_with_id).alias('retailer'))\n",
    "    datasets.append(dataset)\n",
    "\n",
    "dataset_concat = pl.concat(datasets)\n",
    "dataset_concat = dataset_concat.sort(['retailer']+ [c for c in dataset_concat.columns if c.startswith('level')] + ['volume_unit'])\n",
    "\n",
    "dataset_concat.write_csv('data/log/model_4/products_subset_withId.csv', separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "for retailer_without_id in retailers_without_id:\n",
    "    dataset = pl.read_parquet(f'data/silver/without_id/{retailer_without_id}.parquet').rename(lambda column_name: column_name.replace(f\"_{retailer_without_id}\", \"\"))\n",
    "    dataset = dataset.unique(subset=[c for c in dataset.columns if c.startswith('level') or c == 'volume_unit']).with_columns(pl.lit(retailer_without_id).alias('retailer'))\n",
    "    datasets.append(dataset)\n",
    "\n",
    "dataset_concat = pl.concat(datasets)\n",
    "dataset_concat = dataset_concat.sort(['retailer']+ [c for c in dataset_concat.columns if c.startswith('level')] + ['volume_unit'])\n",
    "\n",
    "dataset_concat.write_csv('data/log/model_4/products_subset_withoutId.csv', separator=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract volume unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "for retailer in retailers:\n",
    "    if retailer in retailers_with_id:\n",
    "        dataset = pl.read_parquet(f'data/silver/with_id/{retailer}.parquet').rename({f'volume_unit_{retailer}':'volume_unit'})\n",
    "    else :\n",
    "        dataset = pl.read_parquet(f'data/silver/without_id/{retailer}.parquet').rename({f'volume_unit_{retailer}':'volume_unit'})\n",
    "\n",
    "    dataset = dataset.select('volume_unit').unique().with_columns(pl.lit(retailer).alias('retailer'))\n",
    "    datasets.append(dataset)\n",
    "\n",
    "dataset_concat = pl.concat(datasets).select('retailer', 'volume_unit').sort('retailer')\n",
    "dataset_concat.write_csv('data/log/model_4/volume_unit_subset.csv', separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "\n",
    "from src.utils.profiling import incremental_sublists\n",
    "\n",
    "retailers_with_id = [\n",
    "        \"coup_de_pates\",\n",
    "        \"ds_restauration\",\n",
    "        \"even\",\n",
    "        \"metro\",\n",
    "        \"pomona\",\n",
    "        \"pro_a_pro\",\n",
    "        \"sysco\",\n",
    "        \"transgourmet\",\n",
    "    ]\n",
    "retailers_without_id = [\n",
    "        \"ducreux\",\n",
    "        \"relais_dor\",\n",
    "    ]\n",
    "\n",
    "retailers = retailers_with_id + retailers_without_id\n",
    "\n",
    "wb = xlsxwriter.Workbook(\n",
    "            f\"data/log/model_4/volume_unit_subset_detailed.xlsx\"\n",
    "        )\n",
    "\n",
    "\n",
    "agg_cols_lst = incremental_sublists([f'level_{i}_standard' for i in range(1, 5)])\n",
    "for i, agg_cols in enumerate(agg_cols_lst, start=1):\n",
    "\n",
    "    datasets = []\n",
    "    for retailer in retailers:\n",
    "        if retailer in retailers_with_id:\n",
    "            dataset = pl.read_parquet(f'data/silver/with_id/{retailer}.parquet').rename(lambda column_name: column_name.replace(f\"_{retailer}\", \"\"))\n",
    "            product_col = 'product_id'\n",
    "        else :\n",
    "            dataset = pl.read_parquet(f'data/silver/without_id/{retailer}.parquet').rename(lambda column_name: column_name.replace(f\"_{retailer}\", \"\"))\n",
    "            product_col = 'product_code'\n",
    "\n",
    "        dataset = dataset.group_by(['volume_unit'] + agg_cols).agg(pl.col(product_col).n_unique().alias('nb_products')).unique().with_columns(pl.lit(retailer).alias('retailer')).sort(agg_cols + ['retailer', 'volume_unit'])\n",
    "        datasets.append(dataset)\n",
    "\n",
    "    dataset_concat = pl.concat(datasets)\n",
    "    dataset_concat.write_excel(workbook=wb, worksheet=f\"level_{i}\")\n",
    "\n",
    "wb.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
